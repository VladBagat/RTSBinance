services:
  init-kafka:
      image: alpine
      command: chown -R 1000:1000 /kafka
      volumes:
        - kafka-data:/kafka
      networks:
        - api_network
  kafka:
    image: apache/kafka-native
    volumes:
      - kafka-data:/kafka
    ports:
      - "${KAFKA_HOST_PORT}:9092"
    depends_on:
      init-kafka:
        condition: service_completed_successfully
    environment:
      # Configure datapath
      KAFKA_LOG_DIRS: /kafka

      # Configure listeners for both docker and host communication
      KAFKA_LISTENERS: CONTROLLER://localhost:9091,HOST://0.0.0.0:9092,DOCKER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: HOST://localhost:9092,DOCKER://kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,DOCKER:PLAINTEXT,HOST:PLAINTEXT

      KAFKA_LOG4J_ROOT_LOGLEVEL: 'WARN'
      KAFKA_LOG4J_LOGGERS: 'kafka=WARN,kafka.controller=WARN,kafka.log.LogCleaner=WARN,state.change.logger=WARN,kafka.producer.async.DefaultEventHandler=WARN'
      # Settings required for KRaft mode
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9091

      # Listener to use for broker-to-broker communication
      KAFKA_INTER_BROKER_LISTENER_NAME: DOCKER

      # Required for a single node cluster
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - api_network
    healthcheck:
      test: nc -z localhost 9093 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
  kafka-ui:
    image: kafbat/kafka-ui:main
    ports:
      - ${KAFKA_UI_HOST_PORT}:8080
    environment:
      DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: ${KAFKA_BROKERS}

      LOGGING_LEVEL_ROOT: ERROR
      LOGGING_LEVEL_IO_KAFBAT_UI: ERROR 
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - api_network
  producer:
    build: 
      context: .
      dockerfile: ./producer/Dockerfile
    environment:
      - KAFKA_BROKERS=${KAFKA_BROKERS}
      - RUST_LOG=info
      - PORT=${PRODUCER_PORT}
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - api_network
    
  processor:
    build:
      context: .
      dockerfile: ./processor/Dockerfile
    environment:
      - KAFKA_BROKERS=${KAFKA_BROKERS}
      - RUST_LOG=info
      - PORT=${PROCESSOR_PORT}
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - api_network

  kafka-sink:
    build: ./kafka-sink
    environment:
      - KAFKA_BROKERS=${KAFKA_BROKERS}
      - RUST_LOG=info
      - PORT=${KAFKA_SINK_PORT}
    depends_on:
      - kafka  
      - processor
    networks:
      - api_network
  dashboard:
    build: ./dashboard
    depends_on: 
      - kafka
    environment:
      - PORT=${DASHBOARD_PORT}
    networks:
      - api_network
  nginx:
    build: ./nginx
    ports:
      - ${NGINX_HOST_PORT}:80
    depends_on:
      - producer
      - processor
      - dashboard
    environment:
      - PROCESSOR_PORT=${PROCESSOR_PORT}
      - PRODUCER_PORT=${PRODUCER_PORT}
      - DASHBOARD_PORT=${DASHBOARD_PORT}
      - KAFKA_SINK_PORT=${KAFKA_SINK_PORT}
    networks:
      - api_network

volumes:
  kafka-data:

networks:
  api_network: